{
    "Set 1": [
        {
            "question_no": "Q1",
            "question": "Which of the following best defines deep learning?",
            "options": [
                "A method for shallow neural networks only",
                "A subset of machine learning using multiple layers of neural networks",
                "A rule-based programming technique",
                "A data visualization method"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q2",
            "question": "Which is a primary advantage of deep learning over traditional machine learning? a)",
            "options": [
                "Requires no data",
                "Can automatically learn features from raw data",
                "Works only for small datasets",
                "Needs no computing resources"
            ],
            "answer": "b"
        },
        
        {
            "question_no": "Q3",
            "question": "The dot product of two vectors results in",
            "options": [
                "A scalar",
                "A matrix",
                "A tensor",
                "Another vector"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q4",
            "question": "In deep learning, matrix multiplication is primarily used for:",
            "options": [
                "Calculating gradients only",
                "Transforming inputs through weighted sums in neurons",
                "Reducing overfitting",
                "Hyperparameter tuning"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q5",
            "question": "In probability theory, the sum of probabilities for all possible outcomes is:",
            "options": [
                "Less than 0",
                "Exactly 1",
                "Greater than 1",
                "Equal to the number of events"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q6",
            "question": "Entropy in information theory measures:",
            "options": [
                "The total probability",
                "The uncertainty in a distribution",
                "The correlation between features",
                "The accuracy of a model"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q7",
            "question": "Gradient descent is an example of:",
            "options": [
                "A numerical optimization method",
                "A probability distribution",
                "A matrix factorization technique",
                "A visualization tool"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q8",
            "question": "In numerical computation, underflow occurs when:",
            "options": [
                "Numbers are too small to be represented accurately",
                "Numbers are too large to be represented",
                "The learning rate is too high",
                "A gradient is exactly zero"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q9",
            "question": "In supervised learning, the training data contains:",
            "options": [
                "Only features",
                "Features and corresponding labels",
                "Only labels",
                "Random noise"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q10",
            "question": "Overfitting occurs when a model:",
            "options": [
                "Performs poorly on both training and test data",
                "Performs well on training data but poorly on test data",
                "Performs well on test data only",
                "Ignores training data"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q11",
            "question": "Which of the following is a hyperparameter?",
            "options": [
                "Weight values",
                "Learning rate",
                "Model output",
                "Loss value"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q12",
            "question": "The main purpose of a validation set is to:",
            "options": [
                "Train the model",
                "Test the model performance after deployment",
                "Tune hyperparameters and prevent overfitting",
                "Store unused data"
            ],
            "answer": "c"
        },
        {
            "question_no": "Q13",
            "question": "High bias in a model generally leads to:",
            "options": [
                "Overfitting",
                "Underfitting",
                "Low training error",
                "High variance"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q14",
            "question": "A model with high variance typically:",
            "options": [
                "Performs well on training data but poorly on unseen data",
                "Performs poorly on both training and test data",
                "Ignores the training data",
                "Has no overfitting issues"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q15",
            "question": "Which of the following is an example of supervised learning?",
            "options": [
                "K-means clustering",
                "Principal Component Analysis",
                "Logistic Regression",
                "Autoencoder"
            ],
            "answer": "c"
        },
        {
            "question_no": "Q16",
            "question": "In unsupervised learning, the algorithm:",
            "options": [
                "Uses labeled data",
                "Finds patterns and structures without labels",
                "Requires a test set only",
                "Predicts future values directly"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q17",
            "question": "The “stochastic” in stochastic gradient descent means:",
            "options": [
                "Using a random subset of data for each update",
                "Using the entire dataset for each update",
                "Randomizing the model architecture",
                "Stopping training early"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q18",
            "question": "A common challenge in deep learning is:",
            "options": [
                "Abundance of labeled data",
                "Overfitting due to large model capacity",
                "No need for GPUs",
                "Avoidance of non-linear activation functions"
            ],
            "answer": "b"
        }
    ],
    "Set 2": [
        {
            "question_no": "Q1",
            "question": "The transpose of a matrix changes:",
            "options": [
                "Columns into rows",
                "Rows into columns",
                "Both a and b",
                "Nothing changes"
            ],
            "answer": "c"
        },
        {
            "question_no": "Q2",
            "question": "The identity matrix has:",
            "options": [
                "All ones",
                "Ones on the main diagonal, zeros elsewhere",
                "All zeros",
                "Only positive numbers"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q3",
            "question": "The determinant of a matrix is used to:",
            "options": [
                "Check if the matrix is invertible",
                "Add matrices",
                "Multiply vectors",
                "Change matrix shape"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q4",
            "question": "In deep learning, tensors are:",
            "options": [
                "Only scalars",
                "Multi-dimensional arrays",
                "Probability functions",
                "Loss functions"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q5",
            "question": "Probability values are always between:",
            "options": [
                "0 and 10",
                "-1 and 1",
                "0 and 1",
                "-∞ and ∞"
            ],
            "answer": "c"
        },
        {
            "question_no": "Q6",
            "question": "Conditional probability means:",
            "options": [
                "Probability of event A given event B",
                "Probability of both events happening",
                "Probability without any event",
                "None of the above"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q7",
            "question": "Entropy is a measure of:",
            "options": [
                "Certainty",
                "Uncertainty",
                "Speed",
                "Accuracy"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q8",
            "question": "In classification, cross-entropy loss measures:",
            "options": [
                "Distance between vectors",
                "Difference between predicted and actual probability distributions",
                "Gradient size",
                "Dataset size"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q9",
            "question": "Gradient descent is used for:",
            "options": [
                "Increasing the loss",
                "Finding minimum of a function",
                "Sorting data",
                "Increasing learning rate"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q10",
            "question": "Overflow in computation happens when:",
            "options": [
                "Number is too small",
                "Number is too large to represent",
                "Learning rate is small",
                "Memory is empty"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q11",
            "question": "Numerical instability in deep learning can be reduced by:",
            "options": [
                "Normalization",
                "Adding noise",
                "Increasing bias",
                "Random guessing"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q12",
            "question": "Supervised learning uses:",
            "options": [
                "Labeled data",
                "Unlabeled data",
                "Random data",
                "Only images"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q13",
            "question": "Overfitting means:",
            "options": [
                "Model fits training data too well, fails on test data",
                "Model fits test data only",
                "Model has no errors",
                "Model is undertrained"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q14",
            "question": "Unsupervised learning is mainly used for:",
            "options": [
                "Classification",
                "Clustering",
                "Regression",
                "Loss reduction"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q15",
            "question": "A perceptron is a:",
            "options": [
                "Single-layer neural network unit",
                "Probability function",
                "Loss function",
                "Hyperparameter"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q16",
            "question": "Backpropagation is used to:",
            "options": [
                "Update weights using gradients",
                "Split data into training and testing sets",
                "Increase dataset size",
                "Remove noise from images"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q17",
            "question": "Activation functions add:",
            "options": [
                "Linearity",
                "Non-linearity",
                "Bias removal",
                "Noise"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q18",
            "question": "Model capacity refers to:",
            "options": [
                "Size of dataset",
                "Ability of a model to fit a wide range of functions",
                "GPU memory",
                "Number of labels"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q19",
            "question": "Underfitting occurs when:",
            "options": [
                "Model is too simple to capture patterns",
                "Model fits training data too much",
                "Data is too small",
                "Loss is zero"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q20",
            "question": "Increasing model capacity can lead to:",
            "options": [
                "Underfitting",
                "Overfitting",
                "No change in performance",
                "Lower variance"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q21",
            "question": "Learning rate is a:",
            "options": [
                "Weight value",
                "Hyperparameter",
                "Loss function",
                "Output value"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q22",
            "question": "Validation set is used for:",
            "options": [
                "Training model",
                "Adjusting hyperparameters",
                "Deploying model",
                "Storing raw data"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q23",
            "question": "Batch size controls:",
            "options": [
                "Number of data samples processed before updating weights",
                "Size of validation set",
                "Number of epochs",
                "Number of layers"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q24",
            "question": "High bias leads to:",
            "options": [
                "Underfitting",
                "Overfitting",
                "No learning",
                "Large datasets"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q25",
            "question": "High variance leads to:",
            "options": [
                "Stable predictions",
                "Overfitting",
                "Underfitting",
                "Faster convergence"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q26",
            "question": "Bias-variance trade-off aims to:",
            "options": [
                "Minimize both bias and variance for better generalization",
                "Increase both bias and variance",
                "Maximize loss",
                "Remove labels from dataset"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q27",
            "question": "Bayes’ theorem relates:",
            "options": [
                "Prior, likelihood, and posterior probabilities",
                "Weights and biases",
                "Gradients and learning rate",
                "Loss and accuracy"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q28",
            "question": "In Bayesian statistics, the prior represents:",
            "options": [
                "New evidence",
                "Initial belief before seeing data",
                "Probability after seeing data",
                "Random noise"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q29",
            "question": "In SGD, parameters are updated:",
            "options": [
                "After one data sample or mini-batch",
                "After entire dataset is processed",
                "Without gradients",
                "Only once"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q30",
            "question": "A common challenge in deep learning is:",
            "options": [
                "Lack of overfitting",
                "Need for large labeled datasets",
                "No computation requirement",
                "Avoiding non-linear activation functions"
            ],
            "answer": "b"
        }
    ],
    "Set 3": [
        {
            "question_no": "Q1",
            "question": "A deep feed forward network is also known as:",
            "options": [
                "Recurrent Neural Network",
                "Multilayer Perceptron",
                "Convolutional Neural Network",
                "Decision Tree"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q2",
            "question": "In a feed forward network, data flows:",
            "options": [
                "Back and forth between layers",
                "In one direction from input to output",
                "In loops within the same layer",
                "Randomly between neurons"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q3",
            "question": "The depth of a neural network refers to:",
            "options": [
                "Number of neurons in a layer",
                "Number of layers between input and output",
                "Amount of training data",
                "Size of weights"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q4",
            "question": "The gradient in machine learning represents:",
            "options": [
                "Rate of change of loss with respect to parameters",
                "Number of training samples",
                "Size of the network",
                "Accuracy of the model"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q5",
            "question": "In gradient descent, parameters are updated:",
            "options": [
                "In the opposite direction of the gradient",
                "In the same direction of the gradient",
                "Randomly",
                "Only at the start of training"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q6",
            "question": "Hidden units in a neural network are:",
            "options": [
                "Output neurons only",
                "Neurons between input and output layers",
                "Only convolutional filters",
                "Loss functions"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q7",
            "question": "The activation function of hidden units introduces:",
            "options": [
                "Non-linearity",
                "Bias removal",
                "Noise",
                "Regularization"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q8",
            "question": "The architecture of a neural network includes:",
            "options": [
                "Number of layers and units per layer",
                "Learning rate",
                "Batch size",
                "Loss function only"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q9",
            "question": "Designing deeper architectures can improve:",
            "options": [
                "Representation learning ability",
                "Dataset size",
                "Memory size only",
                "Randomness in weights"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q10",
            "question": "Back-propagation updates weights by:",
            "options": [
                "Passing errors backward through the network",
                "Sending inputs backward",
                "Random guessing",
                "Eliminating gradients"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q11",
            "question": "The chain rule in calculus is essential for:",
            "options": [
                "Computing gradients in back-propagation",
                "Initializing weights",
                "Shuffling data",
                "Choosing activation functions"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q12",
            "question": "Dropout is a regularization technique that:",
            "options": [
                "Removes neurons randomly during training",
                "Increases model depth",
                "Reduces dataset size",
                "Changes the activation function"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q13",
            "question": "Adam optimizer is an example of:",
            "options": [
                "Probability function",
                "Adaptive gradient-based optimization algorithm",
                "Data preprocessing method",
                "Loss function"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q14",
            "question": "In CNNs, convolution layers are mainly used for:",
            "options": [
                "Extracting spatial features",
                "Increasing dataset size",
                "Reducing overfitting only",
                "Adding noise"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q15",
            "question": "Pooling layers in CNNs are used to:",
            "options": [
                "Reduce spatial dimensions of feature maps",
                "Increase learning rate",
                "Add more hidden layers",
                "Perform back-propagation"
            ],
            "answer": "a"
        }
    ],
    "Set 4": [
        {
            "question_no": "Q1",
            "question": "The main feature of recurrent networks is:",
            "options": [
                "Layers connected only in one direction",
                "Loops allowing information to persist over time",
                "Random connections between neurons",
                "Only convolution operations"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q2",
            "question": "Recursive neural networks are mainly used for:",
            "options": [
                "Sequential data only",
                "Tree-structured data",
                "Image classification only",
                "Loss computation"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q3",
            "question": "A key difference between RNNs and recursive nets is:",
            "options": [
                "RNNs process sequences, recursive nets process hierarchies",
                "RNNs are unsupervised, recursive nets are supervised",
                "Recursive nets cannot be trained",
                "RNNs have no activation functions"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q4",
            "question": "RNNs are good at handling:",
            "options": [
                "Independent data points only",
                "Sequential data with temporal dependencies",
                "Random noise",
                "Static images without sequence"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q5",
            "question": "A major drawback of vanilla RNNs is:",
            "options": [
                "They cannot handle inputs at all",
                "Vanishing or exploding gradients",
                "Always overfit small datasets",
                "Lack of hidden layers"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q6",
            "question": "Long Short-Term Memory (LSTM) networks help to:",
            "options": [
                "Reduce training data size",
                "Solve vanishing gradient problem",
                "Increase dataset noise",
                "Replace activation functions"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q7",
            "question": "Deep RNNs stack:",
            "options": [
                "Multiple RNN layers",
                "Multiple convolution layers",
                "Only pooling layers",
                "Decision trees"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q8",
            "question": "Deep RNNs can learn:",
            "options": [
                "More complex sequence patterns",
                "Fewer patterns than shallow RNNs",
                "Only one time step dependency",
                "Without training data"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q9",
            "question": "A recursive network builds:",
            "options": [
                "Representations using a binary tree structure",
                "Only a sequence of identical steps",
                "Feature maps using convolution",
                "Independent linear models"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q10",
            "question": "Recursive nets are often used in:",
            "options": [
                "Natural language parsing",
                "Image resizing",
                "Data normalization",
                "Feature scaling"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q11",
            "question": "Teacher forcing in RNN training means:",
            "options": [
                "Feeding model’s own predictions back into itself",
                "Feeding the correct output from training data into the next step",
                "Stopping training early",
                "Ignoring the hidden state"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q12",
            "question": "Gradient clipping is used to:",
            "options": [
                "Reduce overfitting",
                "Prevent exploding gradients",
                "Increase learning rate",
                "Remove regularization"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q13",
            "question": "Accuracy is best used for:",
            "options": [
                "Balanced datasets",
                "Highly imbalanced datasets",
                "Regression problems",
                "Overfitting prevention"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q14",
            "question": "F1-score is the harmonic mean of:",
            "options": [
                "Accuracy and loss",
                "Precision and recall",
                "Sensitivity and specificity",
                "Recall and accuracy"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q15",
            "question": "The number of hidden units in an RNN affects:",
            "options": [
                "Model capacity",
                "File storage size only",
                "Training dataset length",
                "Type of loss function"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q16",
            "question": "Learning rate controls:",
            "options": [
                "Size of the dataset",
                "Step size in parameter updates",
                "Number of hidden layers",
                "Data shuffling"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q17",
            "question": "If an RNN’s loss is not decreasing, a first check should be:",
            "options": [
                "Whether the learning rate is too high or low",
                "Removing activation functions",
                "Adding more test data",
                "Reducing hidden units to zero"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q18",
            "question": "To detect overfitting, we compare:",
            "options": [
                "Training accuracy vs test accuracy",
                "Learning rate vs batch size",
                "Number of epochs vs dataset size",
                "Loss vs accuracy"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q19",
            "question": "Visualization of gradients during training helps to:",
            "options": [
                "Detect vanishing/exploding gradient problems",
                "Change activation functions",
                "Add noise to data",
                "Increase dataset size"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q20",
            "question": "Using a smaller batch size during debugging can:",
            "options": [
                "Speed up testing and identify errors faster",
                "Remove need for back-propagation",
                "Change data labels",
                "Increase dataset size"
            ],
            "answer": "a"
        }
    ],
    "Set 5": [
        {
            "question_no": "Q1",
            "question": "Probabilistic PCA models:",
            "options": [
                "Only categorical data",
                "Continuous data with Gaussian assumptions",
                "Binary classification problems",
                "Decision trees"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q2",
            "question": "Factor analysis aims to:",
            "options": [
                "Discover hidden variables explaining observed correlations",
                "Reduce dataset size by removing features randomly",
                "Classify data into clusters",
                "Increase dimensionality"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q3",
            "question": "A difference between PCA and probabilistic PCA is:",
            "options": [
                "Probabilistic PCA assumes a Gaussian noise model",
                "PCA works only for images",
                "Probabilistic PCA uses no mathematics",
                "PCA is always supervised"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q4",
            "question": "Factor loadings in factor analysis represent:",
            "options": [
                "Strength of relationship between observed and latent variables",
                "Number of samples in dataset",
                "Noise level in the data",
                "Model accuracy"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q5",
            "question": "Independent Component Analysis (ICA) aims to:",
            "options": [
                "Separate a multivariate signal into statistically independent components",
                "Reduce dimensionality",
                "Increase data correlation",
                "Remove all noise"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q6",
            "question": "ICA is often used in:",
            "options": [
                "Blind source separation problems",
                "Image resizing",
                "Decision tree pruning",
                "Graph neural networks"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q7",
            "question": "Slow Feature Analysis (SFA) extracts:",
            "options": [
                "Features that change slowly over time",
                "Fast-changing signal features",
                "Random features from data",
                "Only static patterns"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q8",
            "question": "SFA is useful in:",
            "options": [
                "Speech recognition",
                "Visual object recognition in dynamic environments",
                "Image compression only",
                "Random data shuffling"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q9",
            "question": "Sparse coding represents data as:",
            "options": [
                "A dense combination of all basis vectors",
                "A combination of few active basis vectors",
                "Random noise",
                "Fully independent components"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q10",
            "question": "Sparse coding is often applied in:",
            "options": [
                "Image denoising",
                "Model overfitting",
                "Data scrambling",
                "Gradient clipping"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q11",
            "question": "Unstructured modeling often struggles with:",
            "options": [
                "Lack of clear relationships between variables",
                "Overuse of labeled datasets",
                "Perfectly clean data",
                "Fixed-size inputs"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q12",
            "question": "A common challenge in unstructured modeling is:",
            "options": [
                "Difficulty in feature extraction",
                "Abundance of labeled data",
                "No need for training",
                "Easy optimization"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q13",
            "question": "Graphs in model structure represent:",
            "options": [
                "Variables as nodes and dependencies as edges",
                "Training loss",
                "Only input features",
                "Weights and biases only"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q14",
            "question": "Graphical models help to:",
            "options": [
                "Capture dependencies between random variables",
                "Increase dataset noise",
                "Remove probabilities",
                "Avoid model training"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q15",
            "question": "Gibbs sampling is used to:",
            "options": [
                "Generate samples from a joint distribution",
                "Remove irrelevant features",
                "Perform gradient descent",
                "Train CNNs"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q16",
            "question": "Sampling from graphical models is useful for:",
            "options": [
                "Approximate inference",
                "Increasing data dimensionality",
                "Model overfitting",
                "Weight initialization only"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q17",
            "question": "Structured modeling incorporates:",
            "options": [
                "Prior knowledge about relationships in data",
                "Only random features",
                "Unrelated datasets",
                "Overfitting intentionally"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q18",
            "question": "One advantage of structured modeling is:",
            "options": [
                "Better interpretability of the model",
                "Increased randomness",
                "Lack of dependencies",
                "Avoidance of prior knowledge"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q19",
            "question": "Structured models are especially useful in:",
            "options": [
                "Natural language processing and computer vision",
                "Random number generation",
                "Model pruning",
                "Noise injection"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q20",
            "question": "Compared to unstructured models, structured models:",
            "options": [
                "Exploit data relationships for better generalization",
                "Ignore variable dependencies",
                "Always require less computation",
                "Use only supervised learning",
                "Supervised learning model",
                "Stochastic recurrent neural network",
                "Deterministic feedforward network",
                "Linear regression model"
            ],
            "answer": "b"
        }
    ],
    "Set 6": [
        {
            "question_no": "Q1",
            "question": "Boltzmann Machines is a type of:",
            "options": [
                "Supervised learning model",
                "Stochastic recurrent neural network",
                "Deterministic feedforward network",
                "Linear regression model"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q2",
            "question": "Boltzmann Machines use which type of units?",
            "options": [
                "Deterministic units only",
                "Binary stochastic units",
                "Continuous deterministic units",
                "Decision tree nodes"
            ],
            "answer": "b"
        },
        {
            "question_no": "Q3",
            "question": "The energy function in a Boltzmann Machine is used to:",
            "options": [
                "Measure the compatibility of a state configuration",
                "Increase gradient size",
                "Select activation function",
                "Shuffle the dataset"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q4",
            "question": "A Restricted Boltzmann Machine (RBM) differs from a general Boltzmann Machine by:",
            "options": [
                "Having connections only between visible and hidden units",
                "Having full connections between all units",
                "Using no hidden layer",
                "Being a convolutional network"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q5",
            "question": "Deep Belief Networks (DBNs) are composed of:",
            "options": [
                "Stacked Restricted Boltzmann Machines",
                "Fully connected feedforward layers only",
                "Only convolution layers",
                "Decision trees"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q6",
            "question": "The training of DBNs often involves:",
            "options": [
                "Layer-wise unsupervised pretraining followed by supervised fine-tuning",
                "Direct supervised learning from scratch",
                "Reinforcement learning only",
                "Random weight assignment"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q7",
            "question": "DBNs are mainly used for:",
            "options": [
                "Feature extraction and generative modeling",
                "Only regression tasks",
                "Increasing batch size",
                "Gradient clipping"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q8",
            "question": "A Deep Boltzmann Machine (DBM) differs from an RBM by:",
            "options": [
                "Having multiple layers of hidden units",
                "Using no visible units",
                "Not using probabilistic modeling",
                "Using only convolution filters"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q9",
            "question": "DBMs are trained using:",
            "options": [
                "Approximate inference techniques like mean-field",
                "Pure backpropagation",
                "Exact maximum likelihood",
                "Random guessing"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q10",
            "question": "Convolutional Boltzmann Machines are designed to:",
            "options": [
                "Capture local spatial features in data",
                "Replace all pooling operations",
                "Work only with text data",
                "Remove convolution operations"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q11",
            "question": "A key advantage of Convolutional Boltzmann Machines is:",
            "options": [
                "Parameter sharing for image feature extraction",
                "Need for very large parameters",
                "Only working on one-dimensional data",
                "Ignoring spatial correlations"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q12",
            "question": "Boltzmann Machines for structured outputs are adapted to:",
            "options": [
                "Predict interdependent output variables",
                "Work only with independent labels",
                "Ignore dependencies in data",
                "Reduce dimensionality"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q13",
            "question": "For sequential outputs, Boltzmann Machines can:",
            "options": [
                "Model temporal dependencies in sequences",
                "Only process independent data",
                "Avoid recurrent connections",
                "Work only with static features"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q14",
            "question": "Directed generative networks define:",
            "options": [
                "A probability distribution using a directed graphical model",
                "Only deterministic mappings",
                "Loss functions only",
                "Convolution kernels"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q15",
            "question": "An example of a directed generative network is:",
            "options": [
                "Variational Autoencoder",
                "DBM",
                "RBM",
                "CNN"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q16",
            "question": "Directed generative models differ from undirected ones because:",
            "options": [
                "They specify conditional probabilities explicitly in one direction",
                "They have no probability interpretation",
                "They avoid learning parameters",
                "They cannot handle hidden variables"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q17",
            "question": "One way to evaluate a generative model is to:",
            "options": [
                "Measure log-likelihood of test data",
                "Only check training loss",
                "Ignore probability distributions",
                "Count number of layers"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q18",
            "question": "The Inception Score is used to evaluate:",
            "options": [
                "Image quality and diversity in generative models",
                "Training speed",
                "Dataset size",
                "Gradient size"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q19",
            "question": "In generative modeling, mode collapse refers to:",
            "options": [
                "Model generating limited variety of outputs",
                "Model generating too many modes",
                "Dataset shrinking",
                "Overfitting"
            ],
            "answer": "a"
        },
        {
            "question_no": "Q20",
            "question": "Human evaluation of generative models is:",
            "options": [
                "Subjective but useful for perceptual quality assessment",
                "Always more accurate than automated metrics",
                "Not needed for GANs",
                "Only used in supervised learning"
            ],
            "answer": "a"
        }
    ]
}